# This file has been automatically generated by `objc2`'s `header-translator`.
# DO NOT EDIT

[package]
name = "objc2-speech"
version.workspace = true
description = "Bindings to the Speech framework"
edition.workspace = true
rust-version.workspace = true
keywords = ["cocoa", "apple", "framework", "macos", "ios"]
categories.workspace = true
repository.workspace = true
license.workspace = true

[lints]
workspace = true

[dependencies]
block2 = { path = "../../crates/block2", version = "0.5.1", default-features = false, optional = true }
objc2 = { path = "../../crates/objc2", version = "0.5.2", default-features = false }
objc2-avf-audio = { path = "../objc2-avf-audio", version = "0.2.2", default-features = false, optional = true }
objc2-core-media = { path = "../objc2-core-media", version = "0.2.2", default-features = false, optional = true }
objc2-foundation = { path = "../objc2-foundation", version = "0.2.2", default-features = false }

[package.metadata.docs.rs]
default-target = "aarch64-apple-darwin"
features = ["all"]
targets = [
    "aarch64-apple-darwin",
    "x86_64-apple-darwin",
    "aarch64-apple-ios",
    "aarch64-apple-ios-macabi",
]

[features]
default = ["std"]

# Currently not possible to turn off, put here for forwards compatibility.
std = ["alloc", "block2?/std", "objc2/std", "objc2-avf-audio?/std", "objc2-core-media?/std", "objc2-foundation/std"]
alloc = ["block2?/alloc", "objc2/alloc", "objc2-avf-audio?/alloc", "objc2-core-media?/alloc", "objc2-foundation/alloc"]
block2 = ["dep:block2", "objc2-avf-audio?/block2", "objc2-core-media?/block2", "objc2-foundation/block2"]
objc2-avf-audio = ["dep:objc2-avf-audio"]
objc2-core-media = ["dep:objc2-core-media", "objc2-avf-audio?/objc2-core-media"]

SFErrors = [
    "objc2-foundation/NSError",
    "objc2-foundation/NSString",
]
SFSpeechLanguageModel = [
    "objc2-foundation/NSError",
    "objc2-foundation/NSObject",
    "objc2-foundation/NSString",
    "objc2-foundation/NSURL",
]
SFSpeechRecognitionMetadata = [
    "objc2-foundation/NSDate",
    "objc2-foundation/NSObject",
]
SFSpeechRecognitionRequest = [
    "objc2-avf-audio?/AVAudioBuffer",
    "objc2-avf-audio?/AVAudioFormat",
    "objc2-core-media?/CMSampleBuffer",
    "objc2-foundation/NSArray",
    "objc2-foundation/NSString",
    "objc2-foundation/NSURL",
]
SFSpeechRecognitionResult = [
    "objc2-foundation/NSArray",
    "objc2-foundation/NSObject",
]
SFSpeechRecognitionTask = [
    "objc2-foundation/NSDate",
    "objc2-foundation/NSError",
]
SFSpeechRecognitionTaskHint = []
SFSpeechRecognizer = [
    "objc2-foundation/NSError",
    "objc2-foundation/NSLocale",
    "objc2-foundation/NSOperation",
    "objc2-foundation/NSSet",
]
SFTranscription = [
    "objc2-foundation/NSArray",
    "objc2-foundation/NSDate",
    "objc2-foundation/NSObject",
    "objc2-foundation/NSString",
]
SFTranscriptionSegment = [
    "objc2-foundation/NSArray",
    "objc2-foundation/NSDate",
    "objc2-foundation/NSObject",
    "objc2-foundation/NSRange",
    "objc2-foundation/NSString",
]
SFVoiceAnalytics = [
    "objc2-foundation/NSArray",
    "objc2-foundation/NSDate",
    "objc2-foundation/NSObject",
    "objc2-foundation/NSValue",
]
all = [
    "SFErrors",
    "SFSpeechLanguageModel",
    "SFSpeechRecognitionMetadata",
    "SFSpeechRecognitionRequest",
    "SFSpeechRecognitionResult",
    "SFSpeechRecognitionTask",
    "SFSpeechRecognitionTaskHint",
    "SFSpeechRecognizer",
    "SFTranscription",
    "SFTranscriptionSegment",
    "SFVoiceAnalytics",
    "block2",
    "objc2-avf-audio",
    "objc2-core-media",
]
